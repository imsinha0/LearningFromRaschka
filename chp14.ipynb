{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T23:50:00.580820Z",
     "start_time": "2024-10-16T23:49:56.877534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import numpy as np"
   ],
   "id": "475185169817df74",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-16T23:50:01.744270Z",
     "start_time": "2024-10-16T23:50:01.739836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def conv1d(x, w, p=0, s=1):\n",
    "    w_rot = np.array(w[::-1])\n",
    "    x_padded = np.array(x)\n",
    "    if p > 0:\n",
    "        zero_pad = np.zeros(shape=p)\n",
    "        x_padded = np.concatenate(\n",
    "            [zero_pad, x_padded, zero_pad])\n",
    "    res = []\n",
    "    for i in range(0, int((len(x_padded) - len(w_rot))) + 1, s):\n",
    "        res.append(np.sum(\n",
    "            x_padded[i:i+w_rot.shape[0]] * w_rot))\n",
    "    return np.array(res)\n",
    "\n",
    "\n",
    "## Testing:\n",
    "x = [1, 3, 2, 4, 5, 6, 1, 3]\n",
    "w = [1, 0, 3, 1, 2]\n",
    "\n",
    "print('Conv1d Implementation:',\n",
    "      conv1d(x, w, p=2, s=1))\n",
    "\n",
    "print('Numpy Results:',\n",
    "      np.convolve(x, w, mode='same')) "
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1d Implementation: [ 5. 14. 16. 26. 24. 34. 19. 22.]\n",
      "Numpy Results: [ 5 14 16 26 24 34 19 22]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T23:50:13.749561Z",
     "start_time": "2024-10-16T23:50:11.721386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import scipy.signal\n",
    "\n",
    "\n",
    "def conv2d(X, W, p=(0, 0), s=(1, 1)):\n",
    "    W_rot = np.array(W)[::-1,::-1]\n",
    "    X_orig = np.array(X)\n",
    "    n1 = X_orig.shape[0] + 2*p[0]\n",
    "    n2 = X_orig.shape[1] + 2*p[1]\n",
    "    X_padded = np.zeros(shape=(n1, n2))\n",
    "    X_padded[p[0]:p[0]+X_orig.shape[0],\n",
    "    p[1]:p[1]+X_orig.shape[1]] = X_orig\n",
    "\n",
    "    res = []\n",
    "    for i in range(0, int((X_padded.shape[0] - \n",
    "                           W_rot.shape[0])/s[0])+1, s[0]):\n",
    "        res.append([])\n",
    "        for j in range(0, int((X_padded.shape[1] - \n",
    "                               W_rot.shape[1])/s[1])+1, s[1]):\n",
    "            X_sub = X_padded[i:i+W_rot.shape[0],\n",
    "                             j:j+W_rot.shape[1]]\n",
    "            res[-1].append(np.sum(X_sub * W_rot))\n",
    "    return(np.array(res))\n",
    "\n",
    "X = [[1, 3, 2, 4], [5, 6, 1, 3], [1, 2, 0, 2], [3, 4, 3, 2]]\n",
    "W = [[1, 0, 3], [1, 2, 1], [0, 1, 1]]\n",
    "\n",
    "print('Conv2d Implementation:\\n',\n",
    "    conv2d(X, W, p=(1, 1), s=(1, 1)))\n",
    "\n",
    "\n",
    "print('SciPy Results:\\n',\n",
    "    scipy.signal.convolve2d(X, W, mode='same'))"
   ],
   "id": "19967528043122ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d Implementation:\n",
      " [[11. 25. 32. 13.]\n",
      " [19. 25. 24. 13.]\n",
      " [13. 28. 25. 17.]\n",
      " [11. 17. 14.  9.]]\n",
      "SciPy Results:\n",
      " [[11 25 32 13]\n",
      " [19 25 24 13]\n",
      " [13 28 25 17]\n",
      " [11 17 14  9]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T23:50:49.411623Z",
     "start_time": "2024-10-16T23:50:49.405350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "loss_func = nn.BCELoss()\n",
    "loss = loss_func(torch.tensor([0.9]), torch.tensor([1.0]))\n",
    "l2_lambda = 0.001\n",
    "\n",
    "conv_layer = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=5)\n",
    "l2_penalty = l2_lambda * sum([(p**2).sum() for p in conv_layer.parameters()])\n",
    "loss_with_penalty = loss + l2_penalty\n",
    "\n",
    "linear_layer = nn.Linear(10, 16)\n",
    "l2_penalty = l2_lambda * sum([(p**2).sum() for p in linear_layer.parameters()])\n",
    "loss_with_penalty = loss + l2_penalty"
   ],
   "id": "f6384fddf381dce6",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T23:51:40.312212Z",
     "start_time": "2024-10-16T23:51:40.304056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "####### Binary Cross-entropy\n",
    "logits = torch.tensor([0.8])\n",
    "probas = torch.sigmoid(logits)\n",
    "target = torch.tensor([1.0])\n",
    "\n",
    "bce_loss_fn = nn.BCELoss()\n",
    "bce_logits_loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(f'BCE (w Probas): {bce_loss_fn(probas, target):.4f}')\n",
    "print(f'BCE (w Logits): {bce_logits_loss_fn(logits, target):.4f}')\n",
    "\n",
    " \n",
    "####### Categorical Cross-entropy\n",
    "logits = torch.tensor([[1.5, 0.8, 2.1]])\n",
    "probas = torch.softmax(logits, dim=1)\n",
    "target = torch.tensor([2])\n",
    "\n",
    "cce_loss_fn = nn.NLLLoss()\n",
    "cce_logits_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f'CCE (w Logits): {cce_logits_loss_fn(logits, target):.4f}')\n",
    "print(f'CCE (w Probas): {cce_loss_fn(torch.log(probas), target):.4f}')"
   ],
   "id": "8c0aafd61dfd8659",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE (w Probas): 0.3711\n",
      "BCE (w Logits): 0.3711\n",
      "CCE (w Logits): 0.5996\n",
      "CCE (w Probas): 0.5996\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T23:51:52.120596Z",
     "start_time": "2024-10-16T23:51:51.082341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torchvision \n",
    "from torchvision import transforms \n",
    "image_path = './'\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "mnist_dataset = torchvision.datasets.MNIST(root=image_path, \n",
    "                                           train=True, \n",
    "                                           transform=transform, \n",
    "                                           download=True)\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "mnist_valid_dataset = Subset(mnist_dataset, torch.arange(10000)) \n",
    "mnist_train_dataset = Subset(mnist_dataset, torch.arange(10000, len(mnist_dataset)))\n",
    "mnist_test_dataset = torchvision.datasets.MNIST(root=image_path, \n",
    "                                           train=False, \n",
    "                                           transform=transform, \n",
    "                                           download=False)"
   ],
   "id": "5fd369b8c20ab7ac",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishaan/miniconda3/envs/LearningFromRaschka/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/ishaan/miniconda3/envs/LearningFromRaschka/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <2D1B8D5C-7891-3680-9CF9-F771AE880676> /Users/ishaan/miniconda3/envs/LearningFromRaschka/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <FF4CD76F-661C-3E38-91B4-8C3E88D7FE2E> /Users/ishaan/miniconda3/envs/LearningFromRaschka/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T23:52:40.696329Z",
     "start_time": "2024-10-16T23:52:40.690353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(mnist_train_dataset, batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(mnist_valid_dataset, batch_size, shuffle=False)"
   ],
   "id": "530617d8bac727df",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T23:52:45.245583Z",
     "start_time": "2024-10-16T23:52:45.231503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('conv1', nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2))\n",
    "model.add_module('relu1', nn.ReLU())        \n",
    "model.add_module('pool1', nn.MaxPool2d(kernel_size=2))   \n",
    "model.add_module('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2))\n",
    "model.add_module('relu2', nn.ReLU())        \n",
    "model.add_module('pool2', nn.MaxPool2d(kernel_size=2))      \n",
    "\n",
    "x = torch.ones((4, 1, 28, 28))\n",
    "model(x).shape"
   ],
   "id": "10a3c771f1000a3e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 7, 7])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T23:52:48.570415Z",
     "start_time": "2024-10-16T23:52:48.565418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.add_module('flatten', nn.Flatten()) \n",
    "\n",
    "x = torch.ones((4, 1, 28, 28))\n",
    "model(x).shape"
   ],
   "id": "ba7be12d16483aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3136])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T23:52:52.083001Z",
     "start_time": "2024-10-16T23:52:52.069331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.add_module('fc1', nn.Linear(3136, 1024)) \n",
    "model.add_module('relu3', nn.ReLU()) \n",
    "model.add_module('dropout', nn.Dropout(p=0.5)) \n",
    "\n",
    "model.add_module('fc2', nn.Linear(1024, 10)) "
   ],
   "id": "448e4f9c1da26091",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T23:53:03.517061Z",
     "start_time": "2024-10-16T23:53:03.514329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = model.to(device) \n"
   ],
   "id": "7dfb78fab5085e90",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-16T23:53:20.626526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, num_epochs, train_dl, valid_dl):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            x_batch = x_batch.to(device) \n",
    "            y_batch = y_batch.to(device) \n",
    "            pred = model(x_batch)\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
    "            is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
    "            accuracy_hist_train[epoch] += is_correct.sum().cpu()\n",
    "\n",
    "        loss_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                x_batch = x_batch.to(device) \n",
    "                y_batch = y_batch.to(device) \n",
    "                pred = model(x_batch)\n",
    "                loss = loss_fn(pred, y_batch)\n",
    "                loss_hist_valid[epoch] += loss.item()*y_batch.size(0) \n",
    "                is_correct = (torch.argmax(pred, dim=1) == y_batch).float() \n",
    "                accuracy_hist_valid[epoch] += is_correct.sum().cpu()\n",
    "\n",
    "        loss_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        accuracy_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        \n",
    "        print(f'Epoch {epoch+1} accuracy: {accuracy_hist_train[epoch]:.4f} val_accuracy: {accuracy_hist_valid[epoch]:.4f}')\n",
    "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid\n",
    "\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 20\n",
    "hist = train(model, num_epochs, train_dl, valid_dl)"
   ],
   "id": "b3c36eaf29fcd39b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T19:13:46.649235Z",
     "start_time": "2024-10-19T19:13:46.527165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "accuracy_test = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_dl:\n",
    "        x_batch = x_batch.to(device) \n",
    "        y_batch = y_batch.to(device) \n",
    "        pred = model(x_batch)[:, 0]\n",
    "        is_correct = ((pred>=0.5).float() == y_batch).float()\n",
    "        accuracy_test += is_correct.sum().cpu()\n",
    " \n",
    "accuracy_test /= len(test_dl.dataset)\n",
    "        \n",
    "print(f'Test accuracy: {accuracy_test:.4f}') "
   ],
   "id": "d4d8dbfcb661e782",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m accuracy_test \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m----> 3\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m x_batch, y_batch \u001B[38;5;129;01min\u001B[39;00m test_dl:\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T19:13:50.493385Z",
     "start_time": "2024-10-19T19:13:50.456559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pred = model(x_batch)[:, 0] * 100\n",
    "\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "for j in range(10, 20):\n",
    "    ax = fig.add_subplot(2, 5, j-10+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(x_batch[j].cpu().permute(1, 2, 0))\n",
    "    if y_batch[j] == 1:\n",
    "        label = 'Smile'\n",
    "    else:\n",
    "        label = 'Not Smile'\n",
    "    ax.text(\n",
    "        0.5, -0.15, \n",
    "        f'GT: {label:s}\\nPr(Smile)={pred[j]:.0f}%', \n",
    "        size=16, \n",
    "        horizontalalignment='center',\n",
    "        verticalalignment='center', \n",
    "        transform=ax.transAxes)"
   ],
   "id": "5268ca9e9ca1bf92",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m(x_batch)[:, \u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[1;32m      3\u001B[0m fig \u001B[38;5;241m=\u001B[39m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m15\u001B[39m, \u001B[38;5;241m7\u001B[39m))\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m20\u001B[39m):\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-19T19:14:00.000824Z",
     "start_time": "2024-10-19T19:13:59.991585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "\n",
    "path = 'models/celeba-cnn.ph'\n",
    "torch.save(model, path)"
   ],
   "id": "feda6f05e4b1a983",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 6\u001B[0m\n\u001B[1;32m      3\u001B[0m     os\u001B[38;5;241m.\u001B[39mmkdir(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodels\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      5\u001B[0m path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodels/celeba-cnn.ph\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 6\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39msave(model, path)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2e736bcc89603550"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
